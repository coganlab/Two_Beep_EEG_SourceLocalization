{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pyvistaqt 3d backend.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Jan 3 2021\n",
    "\n",
    "@author: aidanrogers\n",
    "\"\"\"\n",
    "\n",
    "import mne\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib qt\n",
    "import os, sys\n",
    "#import keyboard\n",
    "import time\n",
    "import pathlib\n",
    "from autoreject import AutoReject\n",
    "import os\n",
    "from os.path import join\n",
    "from os import chdir\n",
    "\n",
    "\n",
    "#mne.viz.set_3d_options(antialias=False, depth_peeling = False, smooth_shading = False)\n",
    "#mne.viz.set_3d_backend('pyvista')\n",
    "\n",
    "if os.name == 'posix': # linux\n",
    "    D_Drive = '/mnt/d/Aidan'\n",
    "    root_dir = '~'\n",
    "    SUBJECTS_DIR = os.getenv('SUBJECTS_DIR')\n",
    "    FREESURFER_HOME = os.getenv('FREESURFER_HOME')\n",
    "elif os.name == 'nt': # windows\n",
    "    D_Drive = 'D:\\Aidan'\n",
    "    root_dir = join(\"C:\",\"Users\",\"aar40\",\"AppData\",\"Local\",\"Packages\",\n",
    "                           \"CanonicalGroupLimited.Ubuntu22.04LTS_79rhkp1fndgsc\",\"LocalState\",\"rootfs\")\n",
    "    FREESURFER_HOME = join(root_dir, \"usr\", \"local\", \"freesurfer\", \"7.3.2\")\n",
    "    SUBJECTS_DIR = join(FREESURFER_HOME,'subjects')\n",
    "else:\n",
    "    raise SystemError('Unknown system os')\n",
    "\n",
    "mne.viz.set_3d_options(antialias=False)\n",
    "mne.viz.set_3d_backend('pyvista')\n",
    "\n",
    "#cd D:\\Aidan\n",
    "%matplotlib qt\n",
    "\n",
    "#D:/Aidan/E1/BrainVision_Recorder/E1_TwoBeeps.vhdr\n",
    "#124_Ch_Test.bvef\n",
    "\n",
    "def sleeper():\n",
    "    \"\"\"\n",
    "    Attempted function to streamline code\n",
    "    \n",
    "    function was used to try and cause pauses between opening plots \n",
    "    for EEG analysis\n",
    "\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        num = 300\n",
    "        \n",
    "        try:\n",
    "            num = float(num)\n",
    "        except ValueError:\n",
    "            print('Please enter in a number.\\n')\n",
    "            continue\n",
    "        print('before: %s' % time.ctime())\n",
    "        time.sleep(num)\n",
    "        print('After: %s\\n' % time.ctime())\n",
    "    \n",
    "\n",
    "def make_montage():\n",
    "    \"\"\"\n",
    "    creates montage, identifies and finds the montage, then makes sure data \n",
    "    is properly aligned with electrode placement we want \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    montage_fname : montage\n",
    "        DESCRIPTION - electrode placement on head of specific subj (128)\n",
    "    subj_num : TYPE\n",
    "        DESCRIPTION - the subject # - who's file are we accessing?\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    montage : montage\n",
    "        DESCRIPTION  - aligned montage\n",
    "    raw : raw\n",
    "        DESCRIPTION - bandpass filtered raw data file\n",
    "\n",
    "    \"\"\"\n",
    "    # have to be in same directory as the file ur looking at to access b/c MNE\n",
    "    os.chdir(D_Drive)\n",
    "    \n",
    "    \n",
    "    montage_fname = input ('Are you using a custom (C) or default (D) montage/electrode placement ')\n",
    "    subj_num = input('what subject # are you analyzing: ')\n",
    "    \n",
    "    \n",
    "    # to be used for the inverse solution (making the bem, coregistraton, covariance etc)\n",
    "    global subj \n",
    "    subj = 'E'+ subj_num\n",
    "    global subject\n",
    "    subject = subj\n",
    "    \n",
    "    # to be used for the inverse solution (making the bem, coregistraton, covariance etc)\n",
    "    # global subjects_dir\n",
    "    # global FREESURFER_HOME\n",
    "    # subjects_dir = 'C:/Users/aar40/Desktop/share/freesurfer/subjects'\n",
    "    # FREESURFER_HOME = 'C:/Users/aar40/Desktop/share/freesurfer'\n",
    "\n",
    "    # mne.set_config(key = subjects_dir, value = 'E46')\n",
    "    \n",
    "    # to identify the correct montage/electrode config\n",
    "    if (montage_fname == 'D'):\n",
    "        montage_name = '124_Ch_Test.bvef'\n",
    "        #load default montage / electrode position\n",
    "        montage = mne.channels.read_custom_montage(montage_name)\n",
    "    elif (montage_fname == 'C'):\n",
    "        #load custom montage / electrode position\n",
    "        montage_name = traverse('CapTrak', subj, subj, '.bvct')\n",
    "        montage = mne.channels.read_dig_captrak(montage_name)\n",
    "    else:\n",
    "        print('invalid input')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    vhdr1 = 'TwoBeeps' #change these to change what type of file you're analyzinbg\n",
    "    vhdr2 = '.vhdr'\n",
    "    vhdr_fname = traverse(os.sep + 'BrainVision_Recorder', subj, vhdr1, vhdr2)\n",
    "   # vhdr_fname = ''\n",
    "\n",
    "    #vhdr_path = 'D:\\Aidan/' + subj + '/BrainVision_Recorder/'     \n",
    "    #vhdr_fname = (filenames for _,_,filenames in os.walk(vhdr_path) if vhdr1 & vhdr2 in filenames)\n",
    "    raw = mne.io.read_raw_brainvision(vhdr_fname, preload=True)\n",
    "    \n",
    "    #Channel renaming dictionary for TwoBeeps subjs E2 - 27\n",
    "    if ((int(subj_num) > 1) & (int(subj_num) < 28 )):\n",
    "        raw = load_data_skewed(raw);\n",
    "    \n",
    "    if (subj != 'E1'): #set eog\n",
    "        raw.set_channel_types({'125':'eog','126':'eog','127':'eog','128':'eog'})\n",
    "        \n",
    "    #apply bandpass filter, set frequency bands\n",
    "    raw.filter(0.5,40)\n",
    "    \n",
    "    #after filtering, remove bad channels in qt plot\n",
    "    raw.plot()\n",
    "    # print(\"wait\")\n",
    "    # wait = input('Press a key to continue: ')\n",
    "    # print(\"continue\")\n",
    "    #cont = keyboard.read_key()\n",
    "    #raw.set_eeg_reference('average')\n",
    "    # raw.set_eeg_reference('average', projection=True)\n",
    "\n",
    "    # raw.set_montage(montage)\n",
    "    # raw.save(pathlib.Path('/mnt/d/Aidan/' + subj + '/Digitization') / 'Captrak_Digitization.fif', overwrite = True)\n",
    "    \n",
    "    return montage, raw\n",
    "\n",
    "def traverse(where, subj, vhdr1, vhdr2):\n",
    "    global vhdr_fname_1\n",
    "    # for dirpath, dirnames, filenames in os.walk('D:\\Aidan/' + subj + where):\n",
    "    for dirpath, dirnames, filenames in os.walk(D_Drive + os.sep + subj + os.sep + where):\n",
    "        for name in filenames:\n",
    "            if vhdr1 in name:\n",
    "                if vhdr2 in name:\n",
    "                    vhdr_fname_1 = dirpath + os.sep + name \n",
    "                    print(vhdr_fname_1)\n",
    "                    print(type(vhdr_fname_1))\n",
    "                    return vhdr_fname_1\n",
    "\n",
    "def load_data_skewed(raw):\n",
    "    '''\n",
    "    takes in raw data file and makes sure the channels (which were missnamed)\n",
    "    are re-aligned given a dictionary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw : raw\n",
    "        DESCRIPTION - raw data file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    raw : raw\n",
    "        DESCRIPTION - data aligned with correct electrode orientation\n",
    "\n",
    "    '''\n",
    "    #Load in EEG file\n",
    "    # raw = mne.io.read_raw_brainvision(vhdr_fname, preload=True)\n",
    "\n",
    "    #Channel renaming dictionary for TwoBeeps subjs E2 - 27\n",
    "    #1-32:97:128, 33-64:65-96, 65-96:33-64. 97-128:1-32\n",
    "    name_dict = {'1':'97','2':'98','3':'99','4':'100','5':'101','6':'102',\n",
    "             '7':'103','8':'104','9':'105','10':'106','11':'107','12':'108',\n",
    "             '13':'109','14':'110','15':'111','16':'112','17':'113',\n",
    "             '18':'114','19':'115','20':'116','21':'117','22':'118',\n",
    "             '23':'119','24':'120','25':'121','26':'122','27':'123',\n",
    "             '28':'124','29':'125','30':'126','31':'127','32':'128','33':'65',\n",
    "             '34':'66','35':'67','36':'68','37':'69','38':'70','39':'71',\n",
    "             '40':'72','41':'73','42':'74','43':'75','44':'76','45':'77',\n",
    "             '46':'78','47':'79','48':'80','49':'81','50':'82','51':'83',\n",
    "             '52':'84','53':'85','54':'86','55':'87','56':'88','57':'89',\n",
    "             '58':'90','59':'91','60':'92','61':'93','62':'94','63':'95',\n",
    "             '64':'96','65':'33','66':'34','67':'35','68':'36','69':'37',\n",
    "             '70':'38','71':'39','72':'40','73':'41','74':'42','75':'43',\n",
    "             '76':'44','77':'45','78':'46','79':'47','80':'48','81':'49',\n",
    "             '82':'50','83':'51','84':'52','85':'53','86':'54','87':'55',\n",
    "             '88':'56','89':'57','90':'58','91':'59','92':'60','93':'61',\n",
    "             '94':'62','95':'63','96':'64','97':'1','98':'2','99':'3',\n",
    "             '100':'4','101':'5','102':'6','103':'7','104':'8','105':'9',\n",
    "             '106':'10','107':'11','108':'12','109':'13','110':'14',\n",
    "             '111':'15','112':'16','113':'17','114':'18','115':'19',\n",
    "             '116':'20','117':'21','118':'22','119':'23','120':'24',\n",
    "             '121':'25','122':'26','123':'27','124':'28','125':'29',\n",
    "             '126':'30','127':'31','128':'32'}\n",
    "    \n",
    "    #list to reorder channels after renaming\n",
    "    order_list = ['1','2','3','4','5','6','7','8','9','10','11','12','13',\n",
    "                  '14','15','16','17','18','19','20','21','22','23','24','25',\n",
    "                  '26','27','28','29','30','31','32','33','34','35','36','37',\n",
    "                  '38','39','40','41','42','43','44','45','46','47','48','49',\n",
    "                  '50','51','52','53','54','55','56','57','58','59','60','61',\n",
    "                  '62','63','64','65','66','67','68','69','70','71','72','73',\n",
    "                  '74','75','76','77','78','79','80','81','82','83','84','85',\n",
    "                  '86','87','88','89','90','91','92','93','94','95','96','97',\n",
    "                  '98','99','100','101','102','103','104','105','106','107',\n",
    "                  '108','109','110','111','112','113','114','115','116','117',\n",
    "                  '118','119','120','121','122','123','124','125','126','127',\n",
    "                  '128']\n",
    "\n",
    "    #rename channels based on above dictionary\n",
    "    raw.rename_channels(name_dict)\n",
    "    \n",
    "    #reorder channels to go sequentially from 1 to 128\n",
    "    raw.reorder_channels(order_list)\n",
    "    \n",
    "    return raw\n",
    "    \n",
    "    \n",
    "def set_data(raw, montage):\n",
    "    '''\n",
    "    common average reference.\n",
    "    take the average signal across all electrodes and take it off the top\n",
    "    reduces noise by 30% - on average\n",
    "    '''\n",
    "    #set reference to average    \n",
    "    raw.set_eeg_reference('average', projection=True)\n",
    "    \n",
    "    #plot data again to remove any remaining bad channels\n",
    "    raw.plot()\n",
    "    \n",
    "    #cont = keyboard.read_key()\n",
    "\n",
    "\n",
    "    return raw\n",
    "    \n",
    "\n",
    "def EOG_check(raw2, ica):\n",
    "    '''\n",
    "    1. regenerates epochs, and evoked (avg epochs)\n",
    "    2. uses find_bads_eog locations and saves those voltages and time periods\n",
    "    3. plot functions (some are commented out)\n",
    "    4. ica.exclude.extend(eog_indices) --> \n",
    "    --> plots newly excluded indices as a copy of raw data\n",
    "    5. display new ERP (doesn't save the data to the main raw file)\n",
    "    '''\n",
    "    eog_epochs=mne.preprocessing.create_eog_epochs(raw, baseline=(-0.5, -0.1))\n",
    "    # eog_epochs.plot_image(combine='mean')\n",
    "    # eog_epochs.average().plot_joint()\n",
    "    eog_average = eog_epochs.average()\n",
    "\n",
    "    # ica.exclude = []\n",
    "    # find which ICs match the EOG pattern\n",
    "    # eog_epochs = mne.preprocessing.create_eog_epochs(raw, baseline=(-0.5, -0.2))\n",
    "    [eog_indices,eog_scores]=ica.find_bads_eog(eog_epochs)\n",
    "    \n",
    "    # barplot of ICA component \"EOG match\" scores\n",
    "    # ica.plot_scores(eog_scores, exclude=eog_indices)\n",
    "    \n",
    "    # plot diagnostics\n",
    "    #ica.plot_properties(raw2, picks=eog_indices)\n",
    "    \n",
    "    # plot ICs applied to raw data, with EOG matches highlighted\n",
    "    # ica.plot_sources(raw2, show_scrollbars=True)\n",
    "    \n",
    "    # plot ICs applied to the averaged EOG epochs, with EOG matches highlighted\n",
    "    ica.plot_sources(eog_average)\n",
    "    \n",
    "    #ica.plot_properties(eog_epochs, picks=eog_indices, psd_args={'fmax': 35.},\n",
    "    #                image_args={'sigma': 1.})\n",
    "    #print(ica.labels_)\n",
    "    \n",
    "    ica.plot_overlay(eog_average, exclude=eog_indices, show=True, title = 'average_indices removed')\n",
    "    ica.plot_overlay(inst = raw2, exclude = eog_indices, title = 'raw before and blink detection')\n",
    "\n",
    "    \n",
    "    ica.exclude.extend(eog_indices)\n",
    "    \n",
    "    reconst_raw = raw2.copy()\n",
    "    ica.apply(inst=reconst_raw)\n",
    "    \n",
    "    erp(reconst_raw, montage)    \n",
    "    \n",
    "    return reconst_raw\n",
    "    \n",
    "\n",
    "def EOG_check_ar(epochs_ar, ica):\n",
    "    '''\n",
    "    1. regenerates epochs, and evoked (avg epochs)\n",
    "    2. uses find_bads_eog locations and saves those voltages and time periods\n",
    "    3. plot functions (some are commented out)\n",
    "    4. ica.exclude.extend(eog_indices) --> \n",
    "    --> plots newly excluded indices as a copy of raw data\n",
    "    5. display new ERP (doesn't save the data to the main raw file)\n",
    "    '''\n",
    "    evoked_ar = epochs_ar.average()\n",
    "\n",
    "    [eog_indices,eog_scores]=ica.find_bads_eog(epochs_ar)\n",
    "\n",
    "    # plot ICs applied to the averaged EOG epochs, with EOG matches highlighted\n",
    "    ica.plot_sources(evoked_ar)\n",
    "    \n",
    "    ica.exclude.extend(eog_indices)\n",
    "    \n",
    "    reconst_raw = epochs_ar.copy()\n",
    "    ica.apply(inst=reconst_raw)\n",
    "    \n",
    "    evoked = reconst_raw.average()\n",
    "    evoked.plot()\n",
    "    \n",
    "    #set ERP to custom montage and plot topoplots\n",
    "    # evoked.set_montage(montage)\n",
    "    times = np.arange(0.0, 0.31, 0.05)\n",
    "    evoked.plot_topomap(times=times, ch_type='eeg')\n",
    "    \n",
    "    return evoked, reconst_raw\n",
    "        \n",
    "    \n",
    "def EOG_annot(raw2, ica):\n",
    "    '''\n",
    "    annotates data for when a bad blink occurs\n",
    "        - occurences (when EOG channels are correlated with specific electrode channel activity)\n",
    "    \n",
    "    Current Issues:\n",
    "        - overwriting stimulus annotations from original data\n",
    "\n",
    "    '''\n",
    "    # make a file, that has the file with the components rempved\n",
    "    #     then plot that clean data\n",
    "    #     0 is the ocular event\n",
    "    # you can reconstruct your, \n",
    "    # Review removing the ICA components on their own\n",
    "    #     project components back into the data\n",
    "    #         then subtract it fromthe data\n",
    "    #             have aw and then signal, then put them back\n",
    "    #             put the data back into original format, then you add it all together,\n",
    "    #             subtract tthe components you don't want\n",
    "                \n",
    "\n",
    "    eog_events = mne.preprocessing.find_eog_events(raw2)\n",
    "    onsets = eog_events[:, 0] / raw.info['sfreq']-0.25 \n",
    "    #take all the indices, divided by the sample rate, 2500hz,-0.25\n",
    "    durations = [0.6] * len( eog_events)\n",
    "    print(len(eog_events))\n",
    "    descriptions = ['bad blink'] * len( eog_events)\n",
    "    blink_annot = mne.Annotations(onsets, durations, descriptions,\n",
    "                                  orig_time=raw.info['meas_date'])\n",
    "    raw2.set_annotations(blink_annot)\n",
    "    eeg_picks = mne.pick_types(raw2.info, meg=False, eeg=True)\n",
    "    raw2.plot(events= eog_events, order=eeg_picks)\n",
    "    #raw.plot(events= eog_indices, order=eeg_picks)\n",
    "\n",
    "    return raw2\n",
    "\n",
    "\n",
    "def erp_blink(raw, montage):\n",
    "    '''\n",
    "    takes annotated data, wherever bad blink is listed\n",
    "    removes the annotation and then plots data\n",
    "\n",
    "    '''\n",
    "    #get events and their IDs from annotations in recorded eeg data\n",
    "    getData = mne.events_from_annotations(raw, event_id={'bad blink':998})\n",
    "\n",
    "\n",
    "    events = getData[0]\n",
    "    event_id = getData[1]\n",
    "\n",
    "    tmin = -0.5\n",
    "    tmax = 1.0\n",
    "    baseline = (-0.5, -0.1)\n",
    "    \n",
    "    #create epochs with baseline subtraction \n",
    "    epochs = mne.Epochs(raw, events=events, event_id=event_id, tmin=tmin, \n",
    "                        tmax=tmax, proj=True, baseline=baseline, preload=True,\n",
    "                        reject_by_annotation=True)\n",
    "    \n",
    "    #create ERP\n",
    "    evoked = epochs.average()\n",
    "    evoked.plot()\n",
    "    \n",
    "    #set ERP to custom montage and plot topoplots\n",
    "    # evoked.set_montage(montage)\n",
    "    times = np.arange(0.0, 0.31, 0.05)\n",
    "    evoked.plot_topomap(times=times, ch_type='eeg')\n",
    "    #cont = keyboard.read_key()\n",
    "    \n",
    "    \n",
    "def erp(raw, montage):  \n",
    "    '''\n",
    "    1. gets stimuli events from annotations in OG data set\n",
    "    2. separate the ID's\n",
    "    3. generate epochs\n",
    "    (slices of time from tmin to tmax based around stimuli occurences)\n",
    "    4. plot the average epoch (evoked)\n",
    "    5. set evoked plot to match the electrode placements\n",
    "    6. plot topographic map of the average epoch centered on the stimuli\n",
    "    \n",
    "    plots the ERP #5\n",
    "\n",
    "    '''\n",
    "    #get events and their IDs from annotations in recorded eeg data\n",
    "    getData = mne.events_from_annotations(raw, event_id={'Stimulus/S  1':1,\n",
    "                                                         'Stimulus/S  2':2,})\n",
    "    #                                                      'Stimulus/S  3':3,\n",
    "    #                                                      'Stimulus/S  4':4})\n",
    "    # print(getData[0])\n",
    "    # print(getData[1])\n",
    "    events = getData[0]\n",
    "    event_id = getData[1]\n",
    "\n",
    "    tmin = -0.5\n",
    "    tmax = 1.0\n",
    "    baseline = (-0.5, -0.1)\n",
    "    \n",
    "    #create epochs with baseline subtraction \n",
    "    epochs = mne.Epochs(raw, events=events, event_id=event_id, tmin=tmin, \n",
    "                        tmax=tmax, proj=True, baseline=baseline, preload=True,\n",
    "                        reject_by_annotation=False)\n",
    "    \n",
    "    #create ERP\n",
    "    evoked = epochs.average()\n",
    "    evoked.plot()\n",
    "    \n",
    "    #set ERP to custom montage and plot topoplots\n",
    "    # evoked.set_montage(montage)\n",
    "    times = np.arange(0.0, 0.31, 0.05)\n",
    "    evoked.plot_topomap(times=times, ch_type='eeg')\n",
    "    \n",
    "    return epochs\n",
    "    #cont = keyboard.read_key()\n",
    " \n",
    "    \n",
    "def ica_func(raw2):\n",
    "    '''\n",
    "    does ICA on the EEG data\n",
    "\n",
    "    '''\n",
    "    #define ica method, default fastica\n",
    "    ica = mne.preprocessing.ICA(method=\"fastica\")\n",
    "    \n",
    "    #fit data to ica\n",
    "    ica.fit(raw2)\n",
    "    \n",
    "\n",
    "    #plot ica components, set inst=data to make plots interactive\n",
    "    ica.plot_components(ch_type='eeg', inst=raw2) #, topomap_args={'data':raw})\n",
    "    \n",
    "    #cont = keyboard.read_key()\n",
    "    # reconst_raw = raw2.copy()\n",
    "    # ica.apply(inst=reconst_raw)\n",
    "    \n",
    "\n",
    "    # ica.plot_overlay(inst = reconst_raw)\n",
    "\n",
    "    return ica\n",
    "\n",
    "def autorej(epochs):\n",
    "    \n",
    "    n_interpolates = np.array([1, 4, 32])\n",
    "    consensus_percs = np.linspace(0, 1.0, 11)\n",
    "    ar = AutoReject(n_interpolates, consensus_percs, random_state = 26042021)\n",
    "    \n",
    "    ar.fit(epochs)\n",
    "    \n",
    "    epochs_ar, reject_log = ar.transform(epochs, return_log = True)\n",
    "    \n",
    "    #reject_log.plot_epochs(epochs, scalings = {\"eeg\":1e-4})\n",
    "    \n",
    "    evoked_ar = epochs_ar.average()\n",
    "    evoked_ar.plot()\n",
    "    \n",
    "    #set ERP to custom montage and plot topoplots\n",
    "    # evoked_ar.set_montage(montage)\n",
    "    times = np.arange(0.0, 0.31, 0.05)\n",
    "    evoked_ar.plot_topomap(times=times, ch_type='eeg')\n",
    "\n",
    "    return epochs_ar\n",
    "\n",
    "def ICA_auto_rej(epochs_ar):\n",
    "    '''\n",
    "    does ICA on the EEG data\n",
    "\n",
    "    '''\n",
    "    #define ica method, default fastica\n",
    "    ica = mne.preprocessing.ICA(method=\"fastica\")\n",
    "    \n",
    "    #fit data to ica\n",
    "    ica.fit(epochs_ar)\n",
    "    \n",
    "\n",
    "    #plot ica components, set inst=data to make plots interactive\n",
    "    ica.plot_components(ch_type='eeg', inst=epochs_ar) #, topomap_args={'data':raw})\n",
    "    \n",
    "    #cont = keyboard.read_key()\n",
    "    # reconst_raw = raw2.copy()\n",
    "    # ica.apply(inst=reconst_raw)\n",
    "    \n",
    "\n",
    "    # ica.plot_overlay(inst = reconst_raw)\n",
    "\n",
    "    return ica\n",
    "\n",
    "\n",
    "## COREGISTRATION STEPS\n",
    "\n",
    "def BEM(SUBJECTS_DIR):\n",
    "    surfaces = mne.bem.make_watershed_bem(subj, subjects_dir = SUBJECTS_DIR)\n",
    "    surfaces = mne.bem.make_scalp_surfaces(subj, subjects_dir = SUBJECTS_DIR)\n",
    "    mne.viz.plot_bem(subject = subj, subjects_dir = SUBJECTS_DIR, orientation = 'coronal', show = True, show_indices=True, mri = 'T1.mgz', show_orientation=True)\n",
    "    mne.bem.make_watershed_bem(subject=subj, subjects_dir=SUBJECTS_DIR, overwrite=True, volume='T1', atlas=False, gcaatlas=False, preflood=None, show=False, copy=False, T1=None, brainmask='ws.mgz', verbose=None)\n",
    "\n",
    "\n",
    "def covariance(reconst_raw):\n",
    "    '''\n",
    "    compute covariance from fresh raw data and epochs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    noise_cov : TYPE\n",
    "        DESCRIPTION.\n",
    "    fig_cov : TYPE\n",
    "        DESCRIPTION.\n",
    "    fig_spectra : TYPE\n",
    "        DESCRIPTION.\n",
    "\n",
    "    '''\n",
    "    noise_cov = mne.compute_covariance(reconst_raw, tmax = 0, method = ['shrunk', 'empirical'], rank = None, verbose = True)\n",
    "    noise_cov = mne.cov.regularize(noise_cov, raw2.info)\n",
    "    \n",
    "    fig_cov, fig_spectra = mne.viz.plot_cov(noise_cov, raw2.info)\n",
    "    \n",
    "    \n",
    "    evoked = reconst_raw.average()\n",
    "    evoked.plot_white(noise_cov, time_unit='s')\n",
    "    \n",
    "    \n",
    "    return noise_cov, fig_cov, fig_spectra, evoked\n",
    "\n",
    "def covariance_raw():\n",
    "    '''\n",
    "    compute covariance from fresh raw data and epochs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    noise_cov : TYPE\n",
    "        DESCRIPTION.\n",
    "    fig_cov : TYPE\n",
    "        DESCRIPTION.\n",
    "    fig_spectra : TYPE\n",
    "        DESCRIPTION.\n",
    "\n",
    "    '''\n",
    "    montage, raw =  make_montage()\n",
    "    \n",
    "    getData = mne.events_from_annotations(raw, event_id={'Stimulus/S  1':1,\n",
    "                                                          'Stimulus/S  2':2,})\n",
    "\n",
    "    events = getData[0]\n",
    "    event_id = getData[1]\n",
    "\n",
    "    tmin = -0.5\n",
    "    tmax = 1.0\n",
    "    baseline = (-0.5, -0.1)\n",
    "    \n",
    "    #create epochs with baseline subtraction \n",
    "    epochs = mne.Epochs(raw, events=events, event_id=event_id, tmin=tmin, \n",
    "                        tmax=tmax, proj=True, baseline=baseline, preload=True,\n",
    "                        reject_by_annotation=False)\n",
    "    \n",
    "    # epochs.save(pathlib.Path('D:/Aidan/' + subj +'/Epochs') / 'epochs_for_source_epo.fif', overwrite = True) #to do co-registration, have to do file path so gui.coreg can take as input\n",
    "    epochs.save(pathlib.Path('/mnt/d/Aidan/' + subj +'/Epochs') / 'epochs_for_source_epo.fif', overwrite = True) #to do co-registration, have to do file path so gui.coreg can take as input\n",
    "    \n",
    "    #noise_cov = mne.compute_covariance(reconst_raw, tmax = 0, method = ['shrunk', 'empirical'], rank = None, verbose = True)\n",
    "    noise_cov = mne.compute_covariance(epochs, tmax = 0, method = ['shrunk', 'empirical'], rank = None, verbose = True)\n",
    "\n",
    "    noise_cov = mne.cov.regularize(noise_cov, epochs.info)\n",
    "    \n",
    "    fig_cov, fig_spectra = mne.viz.plot_cov(noise_cov, raw.info)\n",
    "    \n",
    "    \n",
    "    evoked = epochs.average()\n",
    "    evoked.plot_white(noise_cov, time_unit='s')\n",
    "    \n",
    "    \n",
    "    return noise_cov, fig_cov, fig_spectra, evoked\n",
    "\n",
    "\n",
    "def Co_register(SUBJECTS_DIR):\n",
    "    epochs_fname = pathlib.Path('/mnt/d/Aidan/' + subj +'/Epochs') / 'epochs_for_source_epo.fif'\n",
    "    data = pathlib.Path('/mnt/d/Aidan/' + subj + '/Digitization') / 'Captrak_Digitization.fif'\n",
    "    # epochs_fname = pathlib.Path('D:/Aidan/' + subj +'/Epochs') / 'epochs_for_source_epo.fif'\n",
    "    mne.gui.coregistration(subject = subj, subjects_dir=SUBJECTS_DIR, inst = data)\n",
    "\n",
    "#cd D:\\Aidan\n",
    "#%matplotlib qt\n",
    "\n",
    "def fsa_average(src, SUBJECTS_DIR):\n",
    "    home_path = '/mnt/d/Aidan'\n",
    "    data_path = join(home_path, 'data/')\n",
    "    save_dir_averages = data_path + 'Grand_Averages/Epochs'\n",
    "    save_dir = data_path + 'Grand_Averages'\n",
    "    fsa_average_file = SUBJECTS_DIR + '/fsaverage'\n",
    "    #stc_morph = mne.morph_data(subj, 'fsaverage', SUBJECTS_DIR, n_jobs=-1)\n",
    "    src_morph = mne.morph_source_spaces(src_from = src, subject_to='fsaverage', subjects_dir = SUBJECTS_DIR, surf = 'inflated')\n",
    "    stcs = mne.read_source_estimates(subject = subj,fname = save_dir)\n",
    "    \n",
    "    #fwd = mne.make_forward_solution(info, trans=trans, src=src_morph, bem=bem_sol, meg=False, eeg=True, mindist=5.0, n_jobs=1)\n",
    "    \n",
    "def evoked_grand_average(evoked_data_all):\n",
    "    \n",
    "    home_path = '/mnt/d/Aidan'\n",
    "    data_path = join(home_path, 'data/')\n",
    "    save_dir_averages = data_path + 'Grand_Averages/Epochs'\n",
    "    save_dir = data_path + 'Grand_Averages'\n",
    "    method = 'eLORETA'\n",
    "    \n",
    "def make_morphed_data_average(subject_list):\n",
    "    Inv_path = '/mnt/d/Aidan/Grand_Averages/Inv_op'\n",
    "    Evoked_path = '/mnt/d/Aidan/Grand_Averages/Epochs'\n",
    "    \n",
    "    subj = subject_list[0]\n",
    "    subj_inv_1 = mne.minimum_norm.read_inverse_operator(Inv_path + '/' + subj + 'inv.fif')\n",
    "    subj_ev_1 = mne.read_evokeds(Evoked_path + '/' + subj + '_raw_for_ave.fif')\n",
    "    stc = mne.minimum_norm.apply_inverse(subj_ev_1, subj_ev_1, method = 'eLORETA')\n",
    "    average_source_space = stc.copy() \n",
    "        \n",
    "    for i in range (1, len(subject_list)):\n",
    "        subj = subject_list[i]\n",
    "        subj_inv = mne.minimum_norm.read_inverse_operator(Inv_path + '/' + subj + 'inv.fif')\n",
    "        subj_ev = mne.read_evokeds(Evoked_path + '/' + subj + '_raw_for_Gaverage.fif')\n",
    "        stc = mne.minimum_norm.apply_inverse(subj_ev, subj_ev, method = 'eLORETA')\n",
    "        average_source_space.data += stc.data\n",
    "        \n",
    "    # subj1 = mne.minimum_norm.read_inverse_operator(Inv_path + 'E25' + 'inverse_op.fif')\n",
    "    # subj2 = mne.minimum_norm.read_inverse_operator(Inv_path + 'E29' + 'inverse_op.fif')\n",
    "    # subj3 = mne.minimum_norm.read_inverse_operator(Inv_path + 'E30' + 'inverse_op.fif')\n",
    "    # subj4 = mne.minimum_norm.read_inverse_operator(Inv_path + 'E31' + 'inverse_op.fif')\n",
    "    # subj1_ev = mne.read_evokeds(Evoked_path + 'E25' + '_raw_for_Gaverage.fif')\n",
    "    # mne.minimum_norm.apply_inverse(reconst_evoked, inv_morph, method = 'eLORETA')\n",
    "    \n",
    "    return average_source_space\n",
    "\n",
    "    \n",
    "def make_average_stc(subject_list):\n",
    "    sc_path = '/mnt/d/Aidan/Grand_Averages/Source_Estimates'\n",
    "    \n",
    "    subj = subject_list[0]\n",
    "    stc_lh_1 = mne.read_source_estimate(sc_path + '/' + subj + '_src-lh.stc', subj)\n",
    "    stc_rh_1 = mne.read_source_estimate(sc_path + '/' + subj + '_src-rh.stc', subj)\n",
    "    average_lh = stc_lh_1.copy() \n",
    "    average_rh = stc_rh_1.copy() \n",
    "\n",
    "    for i in range (1, len(subject_list)):\n",
    "        subj = subject_list[i]\n",
    "        stc_lh = mne.read_source_estimate(sc_path + '/' + subj + '_src-lh.stc', subj)\n",
    "        stc_rh = mne.read_source_estimate(sc_path + '/' + subj + '_src-rh.stc', subj)\n",
    "        average_lh += stc_lh_1\n",
    "        average_rh += stc_rh_1\n",
    "        \n",
    "    average_rh = average_rh/(len(subject_list))\n",
    "    average_lh = average_lh/(len(subject_list))\n",
    "\n",
    "    return average_lh, average_rh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage, raw = make_montage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw2 = set_data(raw, montage) #common average reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw2.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = erp(raw2, montage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUTOREJ ROUTE:\n",
    "epochs_ar = autorej(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = ICA_auto_rej(epochs_ar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_sources(epochs_ar, show_scrollbars=True)     # to plot ICA vs time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconst_evoked, reconst_raw = EOG_check_ar(epochs_ar, ica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.exclude = [0,1,3,6,22,47,0,1,3,6,22,47] # MANUAL INPUT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw2.save(pathlib.Path('/mnt/d/Aidan/' + subj + '/Digitization') / 'Captrak_Digitization.fif', overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_path \u001b[39m=\u001b[39m D_Drive \u001b[39m+\u001b[39m  os\u001b[39m.\u001b[39msep \u001b[39m+\u001b[39m subj \u001b[39m+\u001b[39m os\u001b[39m.\u001b[39msep \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDigitization\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      2\u001b[0m data \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPath(data_path) \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCaptrak_Digitization.fif\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'subj' is not defined"
     ]
    }
   ],
   "source": [
    "data_path = D_Drive +  os.sep + subj + os.sep + 'Digitization'\n",
    "data = pathlib.Path(data_path) / 'Captrak_Digitization.fif'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mne')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1fcaa064cd0107f7878d4f34cdffb5ddb7718cbbefb88f7c2981c8f5e5cbb43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
